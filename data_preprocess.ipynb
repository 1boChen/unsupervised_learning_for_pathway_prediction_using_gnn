{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded KGML/hsa01100.kgml\n",
      "Downloaded KGML/hsa01200.kgml\n",
      "Downloaded KGML/hsa01210.kgml\n",
      "Downloaded KGML/hsa01212.kgml\n",
      "Downloaded KGML/hsa01230.kgml\n",
      "Downloaded KGML/hsa01232.kgml\n",
      "Downloaded KGML/hsa01250.kgml\n",
      "Downloaded KGML/hsa01240.kgml\n",
      "Downloaded KGML/hsa00010.kgml\n",
      "Downloaded KGML/hsa00020.kgml\n",
      "Downloaded KGML/hsa00030.kgml\n",
      "Downloaded KGML/hsa00040.kgml\n",
      "Downloaded KGML/hsa00051.kgml\n",
      "Downloaded KGML/hsa00052.kgml\n",
      "Downloaded KGML/hsa00053.kgml\n",
      "Downloaded KGML/hsa00500.kgml\n",
      "Downloaded KGML/hsa00520.kgml\n",
      "Downloaded KGML/hsa00620.kgml\n",
      "Downloaded KGML/hsa00630.kgml\n",
      "Downloaded KGML/hsa00640.kgml\n",
      "Downloaded KGML/hsa00650.kgml\n",
      "Downloaded KGML/hsa00562.kgml\n",
      "Downloaded KGML/hsa00190.kgml\n",
      "Downloaded KGML/hsa00910.kgml\n",
      "Downloaded KGML/hsa00920.kgml\n",
      "Downloaded KGML/hsa00061.kgml\n",
      "Downloaded KGML/hsa00062.kgml\n",
      "Downloaded KGML/hsa00071.kgml\n",
      "Downloaded KGML/hsa00100.kgml\n",
      "Downloaded KGML/hsa00120.kgml\n",
      "Downloaded KGML/hsa00140.kgml\n",
      "Downloaded KGML/hsa00561.kgml\n",
      "Downloaded KGML/hsa00564.kgml\n",
      "Downloaded KGML/hsa00565.kgml\n",
      "Downloaded KGML/hsa00600.kgml\n",
      "Downloaded KGML/hsa00590.kgml\n",
      "Downloaded KGML/hsa00591.kgml\n",
      "Downloaded KGML/hsa00592.kgml\n",
      "Downloaded KGML/hsa01040.kgml\n",
      "Downloaded KGML/hsa00230.kgml\n",
      "Downloaded KGML/hsa00240.kgml\n",
      "Downloaded KGML/hsa00250.kgml\n",
      "Downloaded KGML/hsa00260.kgml\n",
      "Downloaded KGML/hsa00270.kgml\n",
      "Downloaded KGML/hsa00280.kgml\n",
      "Downloaded KGML/hsa00290.kgml\n",
      "Downloaded KGML/hsa00310.kgml\n",
      "Downloaded KGML/hsa00220.kgml\n",
      "Downloaded KGML/hsa00330.kgml\n",
      "Downloaded KGML/hsa00340.kgml\n",
      "Downloaded KGML/hsa00350.kgml\n",
      "Downloaded KGML/hsa00360.kgml\n",
      "Downloaded KGML/hsa00380.kgml\n",
      "Downloaded KGML/hsa00400.kgml\n",
      "Downloaded KGML/hsa00410.kgml\n",
      "Downloaded KGML/hsa00430.kgml\n",
      "Downloaded KGML/hsa00440.kgml\n",
      "Downloaded KGML/hsa00450.kgml\n",
      "Downloaded KGML/hsa00470.kgml\n",
      "Downloaded KGML/hsa00480.kgml\n",
      "Downloaded KGML/hsa00510.kgml\n",
      "Downloaded KGML/hsa00513.kgml\n",
      "Downloaded KGML/hsa00512.kgml\n",
      "Downloaded KGML/hsa00515.kgml\n",
      "Downloaded KGML/hsa00514.kgml\n",
      "Downloaded KGML/hsa00532.kgml\n",
      "Downloaded KGML/hsa00534.kgml\n",
      "Downloaded KGML/hsa00533.kgml\n",
      "Downloaded KGML/hsa00531.kgml\n",
      "Downloaded KGML/hsa00563.kgml\n",
      "Downloaded KGML/hsa00601.kgml\n",
      "Downloaded KGML/hsa00603.kgml\n",
      "Downloaded KGML/hsa00604.kgml\n",
      "Downloaded KGML/hsa00511.kgml\n",
      "Downloaded KGML/hsa00730.kgml\n",
      "Downloaded KGML/hsa00740.kgml\n",
      "Downloaded KGML/hsa00750.kgml\n",
      "Downloaded KGML/hsa00760.kgml\n",
      "Downloaded KGML/hsa00770.kgml\n",
      "Downloaded KGML/hsa00780.kgml\n",
      "Downloaded KGML/hsa00785.kgml\n",
      "Downloaded KGML/hsa00790.kgml\n",
      "Downloaded KGML/hsa00670.kgml\n",
      "Downloaded KGML/hsa00830.kgml\n",
      "Downloaded KGML/hsa00860.kgml\n",
      "Downloaded KGML/hsa00130.kgml\n",
      "Downloaded KGML/hsa00900.kgml\n",
      "Downloaded KGML/hsa00232.kgml\n",
      "Downloaded KGML/hsa00524.kgml\n",
      "Downloaded KGML/hsa00980.kgml\n",
      "Downloaded KGML/hsa00982.kgml\n",
      "Downloaded KGML/hsa00983.kgml\n",
      "Downloaded KGML/hsa03020.kgml\n",
      "Downloaded KGML/hsa03022.kgml\n",
      "Downloaded KGML/hsa03040.kgml\n",
      "Downloaded KGML/hsa03010.kgml\n",
      "Downloaded KGML/hsa00970.kgml\n",
      "Downloaded KGML/hsa03013.kgml\n",
      "Downloaded KGML/hsa03015.kgml\n",
      "Downloaded KGML/hsa03008.kgml\n",
      "Downloaded KGML/hsa03060.kgml\n",
      "Downloaded KGML/hsa04141.kgml\n",
      "Downloaded KGML/hsa04130.kgml\n",
      "Downloaded KGML/hsa04120.kgml\n",
      "Downloaded KGML/hsa04122.kgml\n",
      "Downloaded KGML/hsa03050.kgml\n",
      "Downloaded KGML/hsa03018.kgml\n",
      "Downloaded KGML/hsa03030.kgml\n",
      "Downloaded KGML/hsa03410.kgml\n",
      "Downloaded KGML/hsa03420.kgml\n",
      "Downloaded KGML/hsa03430.kgml\n",
      "Downloaded KGML/hsa03440.kgml\n",
      "Downloaded KGML/hsa03450.kgml\n",
      "Downloaded KGML/hsa03460.kgml\n",
      "Downloaded KGML/hsa03082.kgml\n",
      "Downloaded KGML/hsa03083.kgml\n",
      "Downloaded KGML/hsa03250.kgml\n",
      "Downloaded KGML/hsa03260.kgml\n",
      "Downloaded KGML/hsa03264.kgml\n",
      "Downloaded KGML/hsa03265.kgml\n",
      "Downloaded KGML/hsa03266.kgml\n",
      "Downloaded KGML/hsa03267.kgml\n",
      "Downloaded KGML/hsa02010.kgml\n",
      "Downloaded KGML/hsa04010.kgml\n",
      "Downloaded KGML/hsa04012.kgml\n",
      "Downloaded KGML/hsa04014.kgml\n",
      "Downloaded KGML/hsa04015.kgml\n",
      "Downloaded KGML/hsa04310.kgml\n",
      "Downloaded KGML/hsa04330.kgml\n",
      "Downloaded KGML/hsa04340.kgml\n",
      "Downloaded KGML/hsa04350.kgml\n",
      "Downloaded KGML/hsa04390.kgml\n",
      "Downloaded KGML/hsa04392.kgml\n",
      "Downloaded KGML/hsa04370.kgml\n",
      "Downloaded KGML/hsa04371.kgml\n",
      "Downloaded KGML/hsa04630.kgml\n",
      "Downloaded KGML/hsa04064.kgml\n",
      "Downloaded KGML/hsa04668.kgml\n",
      "Downloaded KGML/hsa04066.kgml\n",
      "Downloaded KGML/hsa04068.kgml\n",
      "Downloaded KGML/hsa04020.kgml\n",
      "Downloaded KGML/hsa04070.kgml\n",
      "Downloaded KGML/hsa04072.kgml\n",
      "Downloaded KGML/hsa04071.kgml\n",
      "Downloaded KGML/hsa04024.kgml\n",
      "Downloaded KGML/hsa04022.kgml\n",
      "Downloaded KGML/hsa04151.kgml\n",
      "Downloaded KGML/hsa04152.kgml\n",
      "Downloaded KGML/hsa04150.kgml\n",
      "Downloaded KGML/hsa04080.kgml\n",
      "Downloaded KGML/hsa04060.kgml\n",
      "Downloaded KGML/hsa04061.kgml\n",
      "Downloaded KGML/hsa04512.kgml\n",
      "Downloaded KGML/hsa04514.kgml\n",
      "Downloaded KGML/hsa04144.kgml\n",
      "Downloaded KGML/hsa04145.kgml\n",
      "Downloaded KGML/hsa04142.kgml\n",
      "Downloaded KGML/hsa04146.kgml\n",
      "Downloaded KGML/hsa04140.kgml\n",
      "Downloaded KGML/hsa04136.kgml\n",
      "Downloaded KGML/hsa04137.kgml\n",
      "Downloaded KGML/hsa04148.kgml\n",
      "Downloaded KGML/hsa04110.kgml\n",
      "Downloaded KGML/hsa04114.kgml\n",
      "Downloaded KGML/hsa04210.kgml\n",
      "Downloaded KGML/hsa04215.kgml\n",
      "Downloaded KGML/hsa04216.kgml\n",
      "Downloaded KGML/hsa04217.kgml\n",
      "Downloaded KGML/hsa04115.kgml\n",
      "Downloaded KGML/hsa04218.kgml\n",
      "Downloaded KGML/hsa04510.kgml\n",
      "Downloaded KGML/hsa04520.kgml\n",
      "Downloaded KGML/hsa04530.kgml\n",
      "Downloaded KGML/hsa04540.kgml\n",
      "Downloaded KGML/hsa04550.kgml\n",
      "Downloaded KGML/hsa04814.kgml\n",
      "Downloaded KGML/hsa04810.kgml\n",
      "Downloaded KGML/hsa04640.kgml\n",
      "Downloaded KGML/hsa04610.kgml\n",
      "Downloaded KGML/hsa04611.kgml\n",
      "Downloaded KGML/hsa04613.kgml\n",
      "Downloaded KGML/hsa04620.kgml\n",
      "Downloaded KGML/hsa04621.kgml\n",
      "Downloaded KGML/hsa04622.kgml\n",
      "Downloaded KGML/hsa04623.kgml\n",
      "Downloaded KGML/hsa04625.kgml\n",
      "Downloaded KGML/hsa04650.kgml\n",
      "Downloaded KGML/hsa04612.kgml\n",
      "Downloaded KGML/hsa04660.kgml\n",
      "Downloaded KGML/hsa04658.kgml\n",
      "Downloaded KGML/hsa04659.kgml\n",
      "Downloaded KGML/hsa04657.kgml\n",
      "Downloaded KGML/hsa04662.kgml\n",
      "Downloaded KGML/hsa04664.kgml\n",
      "Downloaded KGML/hsa04666.kgml\n",
      "Downloaded KGML/hsa04670.kgml\n",
      "Downloaded KGML/hsa04672.kgml\n",
      "Downloaded KGML/hsa04062.kgml\n",
      "Downloaded KGML/hsa04911.kgml\n",
      "Downloaded KGML/hsa04910.kgml\n",
      "Downloaded KGML/hsa04922.kgml\n",
      "Downloaded KGML/hsa04923.kgml\n",
      "Downloaded KGML/hsa04920.kgml\n",
      "Downloaded KGML/hsa03320.kgml\n",
      "Downloaded KGML/hsa04929.kgml\n",
      "Downloaded KGML/hsa04912.kgml\n",
      "Downloaded KGML/hsa04913.kgml\n",
      "Downloaded KGML/hsa04915.kgml\n",
      "Downloaded KGML/hsa04914.kgml\n",
      "Downloaded KGML/hsa04917.kgml\n",
      "Downloaded KGML/hsa04921.kgml\n",
      "Downloaded KGML/hsa04926.kgml\n",
      "Downloaded KGML/hsa04935.kgml\n",
      "Downloaded KGML/hsa04918.kgml\n",
      "Downloaded KGML/hsa04919.kgml\n",
      "Downloaded KGML/hsa04928.kgml\n",
      "Downloaded KGML/hsa04916.kgml\n",
      "Downloaded KGML/hsa04924.kgml\n",
      "Downloaded KGML/hsa04614.kgml\n",
      "Downloaded KGML/hsa04925.kgml\n",
      "Downloaded KGML/hsa04927.kgml\n",
      "Downloaded KGML/hsa04260.kgml\n",
      "Downloaded KGML/hsa04261.kgml\n",
      "Downloaded KGML/hsa04270.kgml\n",
      "Downloaded KGML/hsa04970.kgml\n",
      "Downloaded KGML/hsa04971.kgml\n",
      "Downloaded KGML/hsa04972.kgml\n",
      "Downloaded KGML/hsa04976.kgml\n",
      "Downloaded KGML/hsa04973.kgml\n",
      "Downloaded KGML/hsa04974.kgml\n",
      "Downloaded KGML/hsa04975.kgml\n",
      "Downloaded KGML/hsa04979.kgml\n",
      "Downloaded KGML/hsa04977.kgml\n",
      "Downloaded KGML/hsa04978.kgml\n",
      "Downloaded KGML/hsa04962.kgml\n",
      "Downloaded KGML/hsa04960.kgml\n",
      "Downloaded KGML/hsa04961.kgml\n",
      "Downloaded KGML/hsa04964.kgml\n",
      "Downloaded KGML/hsa04966.kgml\n",
      "Downloaded KGML/hsa04724.kgml\n",
      "Downloaded KGML/hsa04727.kgml\n",
      "Downloaded KGML/hsa04725.kgml\n",
      "Downloaded KGML/hsa04728.kgml\n",
      "Downloaded KGML/hsa04726.kgml\n",
      "Downloaded KGML/hsa04720.kgml\n",
      "Downloaded KGML/hsa04730.kgml\n",
      "Downloaded KGML/hsa04723.kgml\n",
      "Downloaded KGML/hsa04721.kgml\n",
      "Downloaded KGML/hsa04722.kgml\n",
      "Downloaded KGML/hsa04744.kgml\n",
      "Downloaded KGML/hsa04740.kgml\n",
      "Downloaded KGML/hsa04742.kgml\n",
      "Downloaded KGML/hsa04750.kgml\n",
      "Downloaded KGML/hsa04360.kgml\n",
      "Downloaded KGML/hsa04380.kgml\n",
      "Downloaded KGML/hsa04211.kgml\n",
      "Downloaded KGML/hsa04213.kgml\n",
      "Downloaded KGML/hsa04710.kgml\n",
      "Downloaded KGML/hsa04713.kgml\n",
      "Downloaded KGML/hsa04714.kgml\n",
      "Downloaded KGML/hsa05200.kgml\n",
      "Downloaded KGML/hsa05202.kgml\n",
      "Downloaded KGML/hsa05206.kgml\n",
      "Downloaded KGML/hsa05205.kgml\n",
      "Downloaded KGML/hsa05204.kgml\n",
      "Downloaded KGML/hsa05207.kgml\n",
      "Downloaded KGML/hsa05208.kgml\n",
      "Downloaded KGML/hsa05203.kgml\n",
      "Downloaded KGML/hsa05230.kgml\n",
      "Downloaded KGML/hsa05231.kgml\n",
      "Downloaded KGML/hsa05235.kgml\n",
      "Downloaded KGML/hsa05210.kgml\n",
      "Downloaded KGML/hsa05212.kgml\n",
      "Downloaded KGML/hsa05225.kgml\n",
      "Downloaded KGML/hsa05226.kgml\n",
      "Downloaded KGML/hsa05214.kgml\n",
      "Downloaded KGML/hsa05216.kgml\n",
      "Downloaded KGML/hsa05221.kgml\n",
      "Downloaded KGML/hsa05220.kgml\n",
      "Downloaded KGML/hsa05217.kgml\n",
      "Downloaded KGML/hsa05218.kgml\n",
      "Downloaded KGML/hsa05211.kgml\n",
      "Downloaded KGML/hsa05219.kgml\n",
      "Downloaded KGML/hsa05215.kgml\n",
      "Downloaded KGML/hsa05213.kgml\n",
      "Downloaded KGML/hsa05224.kgml\n",
      "Downloaded KGML/hsa05222.kgml\n",
      "Downloaded KGML/hsa05223.kgml\n",
      "Downloaded KGML/hsa05166.kgml\n",
      "Downloaded KGML/hsa05170.kgml\n",
      "Downloaded KGML/hsa05161.kgml\n",
      "Downloaded KGML/hsa05160.kgml\n",
      "Downloaded KGML/hsa05171.kgml\n",
      "Downloaded KGML/hsa05164.kgml\n",
      "Downloaded KGML/hsa05162.kgml\n",
      "Downloaded KGML/hsa05168.kgml\n",
      "Downloaded KGML/hsa05163.kgml\n",
      "Downloaded KGML/hsa05167.kgml\n",
      "Downloaded KGML/hsa05169.kgml\n",
      "Downloaded KGML/hsa05165.kgml\n",
      "Downloaded KGML/hsa05110.kgml\n",
      "Downloaded KGML/hsa05120.kgml\n",
      "Downloaded KGML/hsa05130.kgml\n",
      "Downloaded KGML/hsa05132.kgml\n",
      "Downloaded KGML/hsa05131.kgml\n",
      "Downloaded KGML/hsa05135.kgml\n",
      "Downloaded KGML/hsa05133.kgml\n",
      "Downloaded KGML/hsa05134.kgml\n",
      "Downloaded KGML/hsa05150.kgml\n",
      "Downloaded KGML/hsa05152.kgml\n",
      "Downloaded KGML/hsa05100.kgml\n",
      "Downloaded KGML/hsa05146.kgml\n",
      "Downloaded KGML/hsa05144.kgml\n",
      "Downloaded KGML/hsa05145.kgml\n",
      "Downloaded KGML/hsa05140.kgml\n",
      "Downloaded KGML/hsa05142.kgml\n",
      "Downloaded KGML/hsa05143.kgml\n",
      "Downloaded KGML/hsa05310.kgml\n",
      "Downloaded KGML/hsa05322.kgml\n",
      "Downloaded KGML/hsa05323.kgml\n",
      "Downloaded KGML/hsa05320.kgml\n",
      "Downloaded KGML/hsa05321.kgml\n",
      "Downloaded KGML/hsa05330.kgml\n",
      "Downloaded KGML/hsa05332.kgml\n",
      "Downloaded KGML/hsa05340.kgml\n",
      "Downloaded KGML/hsa05010.kgml\n",
      "Downloaded KGML/hsa05012.kgml\n",
      "Downloaded KGML/hsa05014.kgml\n",
      "Downloaded KGML/hsa05016.kgml\n",
      "Downloaded KGML/hsa05017.kgml\n",
      "Downloaded KGML/hsa05020.kgml\n",
      "Downloaded KGML/hsa05022.kgml\n",
      "Downloaded KGML/hsa05030.kgml\n",
      "Downloaded KGML/hsa05031.kgml\n",
      "Downloaded KGML/hsa05032.kgml\n",
      "Downloaded KGML/hsa05033.kgml\n",
      "Downloaded KGML/hsa05034.kgml\n",
      "Downloaded KGML/hsa05417.kgml\n",
      "Downloaded KGML/hsa05418.kgml\n",
      "Downloaded KGML/hsa05410.kgml\n",
      "Downloaded KGML/hsa05412.kgml\n",
      "Downloaded KGML/hsa05414.kgml\n",
      "Downloaded KGML/hsa05415.kgml\n",
      "Downloaded KGML/hsa05416.kgml\n",
      "Downloaded KGML/hsa04930.kgml\n",
      "Downloaded KGML/hsa04940.kgml\n",
      "Downloaded KGML/hsa04950.kgml\n",
      "Downloaded KGML/hsa04936.kgml\n",
      "Downloaded KGML/hsa04932.kgml\n",
      "Downloaded KGML/hsa04931.kgml\n",
      "Downloaded KGML/hsa04933.kgml\n",
      "Downloaded KGML/hsa04934.kgml\n",
      "Downloaded KGML/hsa01521.kgml\n",
      "Downloaded KGML/hsa01524.kgml\n",
      "Downloaded KGML/hsa01523.kgml\n",
      "Downloaded KGML/hsa01522.kgml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the base URL for the KEGG API\n",
    "BASE_URL = \"http://rest.kegg.jp/\"\n",
    "\n",
    "# Function to get the list of human pathways\n",
    "def get_human_pathways():\n",
    "    response = requests.get(f\"{BASE_URL}list/pathway/hsa\")\n",
    "    if response.ok:\n",
    "        pathway_ids = response.text\n",
    "        # The pathway identifiers are in the first column, separated by a tab character\n",
    "        return [line.split(\"\\t\")[0].replace('path:', '') for line in pathway_ids.strip().split(\"\\n\")]\n",
    "    else:\n",
    "        print(\"Failed to retrieve pathway list\")\n",
    "        return []\n",
    "\n",
    "# Function to download KGML files for each pathway\n",
    "def download_kgml_files(pathway_ids):\n",
    "    # Create a directory named 'KGML' if it doesn't exist\n",
    "    os.makedirs('KGML', exist_ok=True)\n",
    "\n",
    "    for pathway_id in pathway_ids:\n",
    "        response = requests.get(f\"{BASE_URL}get/{pathway_id}/kgml\")\n",
    "        if response.ok:\n",
    "            # Save the file to the 'KGML' directory\n",
    "            filename = f\"KGML/{pathway_id}.kgml\"\n",
    "            with open(filename, 'w') as file:\n",
    "                file.write(response.text)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download KGML for {pathway_id}\")\n",
    "\n",
    "# Main function to perform the download\n",
    "def main():\n",
    "    pathway_ids = get_human_pathways()\n",
    "    download_kgml_files(pathway_ids)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "# Function to parse a single KGML file and extract the relevant information\n",
    "def parse_kgml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    pathway_name = root.get('name').split(\":\")[-1]  # Assuming the pathway name is like \"path:hsa04810\"\n",
    "    pathway_info = {'pathway': pathway_name, 'relations': defaultdict(int)}\n",
    "\n",
    "    entries = {}\n",
    "    for entry in root.findall('entry'):\n",
    "        entry_id = entry.get('id')\n",
    "        entities = entry.get('name').split()\n",
    "        entries[entry_id] = entities\n",
    "\n",
    "    for relation in root.findall('relation'):\n",
    "        entry1 = relation.get('entry1')\n",
    "        entry2 = relation.get('entry2')\n",
    "        interaction_types = [subtype.get('name') for subtype in relation.findall('subtype')]\n",
    "\n",
    "        # Generate all possible combinations of relations\n",
    "        for starter, receiver in product(entries.get(entry1, []), entries.get(entry2, [])):\n",
    "            pathway_info['relations'][(starter, receiver, tuple(interaction_types))] += 1\n",
    "\n",
    "        # If the relation is reversible, add the reverse relations as well\n",
    "        if 'reversible' in interaction_types:\n",
    "            for starter, receiver in product(entries.get(entry2, []), entries.get(entry1, [])):\n",
    "                pathway_info['relations'][(starter, receiver, tuple(interaction_types))] += 1\n",
    "\n",
    "    return pathway_info\n",
    "\n",
    "# Function to process all KGML files and write the CSV\n",
    "def process_kgml_files(kgml_directory, output_csv, log_file):\n",
    "    all_pathway_info = defaultdict(lambda: defaultdict(int))\n",
    "    failed_files = []\n",
    "\n",
    "    # Process each KGML file and aggregate the information\n",
    "    for filename in os.listdir(kgml_directory):\n",
    "        if filename.endswith('.kgml'):\n",
    "            try:\n",
    "                pathway_info = parse_kgml(os.path.join(kgml_directory, filename))\n",
    "                for relation, count in pathway_info['relations'].items():\n",
    "                    all_pathway_info[relation][pathway_info['pathway']] += count\n",
    "            except ET.ParseError as e:\n",
    "                # Log the error with the filename\n",
    "                failed_files.append((filename, str(e)))\n",
    "\n",
    "    # Write the failed files and errors to a log file\n",
    "    with open(log_file, 'w') as logf:\n",
    "        for file, error in failed_files:\n",
    "            logf.write(f\"{file}: {error}\\n\")\n",
    "    \n",
    "    # Write the information to a CSV file\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['starter_ID', 'receiver_ID', 'interaction_types', 'pathways', 'credibility']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for (starter, receiver, interaction_types), pathways_info in all_pathway_info.items():\n",
    "            pathway_counts = \"; \".join(f\"{path} ({count})\" for path, count in pathways_info.items())\n",
    "            total_count = sum(pathways_info.values())\n",
    "            writer.writerow({\n",
    "                'starter_ID': starter,\n",
    "                'receiver_ID': receiver,\n",
    "                'interaction_types': \", \".join(interaction_types),\n",
    "                'pathways': pathway_counts,\n",
    "                'credibility': total_count\n",
    "            })\n",
    "\n",
    "# Main function to start the process\n",
    "def main():\n",
    "    kgml_directory = 'KGML'\n",
    "    output_csv = 'pathway_relations.csv'\n",
    "    log_file = 'failed_kgml_files.txt'\n",
    "    process_kgml_files(kgml_directory, output_csv, log_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it seems that the code parsed all the KGML file without giving out single one failed cased and stored the results in pathway_relations.csv. However, by checking the pathway map closer, I found that there are two relations, one is named relation, and the other is named reaction, only reaction have reversible and irrevesible type, so we don't need to deal with the reversible and irreversible relations when parsing the KGML only to extract the pathway relations. Now, I want you to revise the code to extract all the relations again, but also record the relation type in the finalized csv file. Moreover, when recording the source of the relation, part from using the name of the pathway map like path:hsa00250, please also include the title of the map: path:hsa00250 Alanine, aspartate and glutamate metabolism. The name and title of the map is stored in KGML in the following format: \"\"\"<pathway name=\"path:hsa00250\" org=\"hsa\" number=\"00250\"\n",
    "         title=\"Alanine, aspartate and glutamate metabolism\"\n",
    "         image=\"https://www.kegg.jp/kegg/pathway/hsa/hsa00250.png\"\n",
    "         link=\"https://www.kegg.jp/kegg-bin/show_pathway?hsa00250\">\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "def parse_kgml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    pathway_id = root.get('name')\n",
    "    pathway_title = root.get('title')\n",
    "    pathway_source = f\"{pathway_id} {pathway_title}\"\n",
    "\n",
    "    entries = {}\n",
    "    for entry in root.findall('entry'):\n",
    "        entry_id = entry.get('id')\n",
    "        entities = entry.get('name').split()\n",
    "        entries[entry_id] = entities\n",
    "\n",
    "    relations = defaultdict(lambda: {'count': 0, 'pathways': set()})\n",
    "    for relation in root.findall('relation'):\n",
    "        entry1 = relation.get('entry1')\n",
    "        entry2 = relation.get('entry2')\n",
    "        relation_type = relation.get('type')\n",
    "        subtypes = [subtype.get('name') for subtype in relation.findall('subtype') if subtype.get('name') not in [\"missing interaction\", \"indirect effect\"]]\n",
    "\n",
    "        if not subtypes:\n",
    "            continue\n",
    "\n",
    "        for starter, receiver in product(entries.get(entry1, []), entries.get(entry2, [])):\n",
    "            for subtype_name in subtypes:\n",
    "                # Create a unique key for each relation\n",
    "                key = (starter, receiver, relation_type, subtype_name)\n",
    "                relations[key]['count'] += 1\n",
    "                relations[key]['pathways'].add(pathway_source)\n",
    "\n",
    "    # Transform relations into a list of dictionaries for easier CSV writing\n",
    "    relations_info = [\n",
    "        {\n",
    "            'starter_ID': key[0],\n",
    "            'receiver_ID': key[1],\n",
    "            'relation_type': key[2],\n",
    "            'subtype_name': key[3],\n",
    "            'pathway_source': ', '.join(rel['pathways']),\n",
    "            'credibility': rel['count']\n",
    "        }\n",
    "        for key, rel in relations.items()\n",
    "    ]\n",
    "\n",
    "    reactions = []\n",
    "    for reaction in root.findall('reaction'):\n",
    "        reaction_id = reaction.get('id')\n",
    "        reaction_type = reaction.get('type')\n",
    "        substrates = [substrate.get('name') for substrate in reaction.findall('substrate')]\n",
    "        products = [product.get('name') for product in reaction.findall('product')]\n",
    "\n",
    "        reaction_entry = {\n",
    "            'id': reaction_id,\n",
    "            'type': reaction_type,\n",
    "            'pathway': pathway_source,\n",
    "            'substrates': substrates,\n",
    "            'products': products\n",
    "        }\n",
    "        reactions.append(reaction_entry)\n",
    "\n",
    "        # If the reaction is reversible, add a reversed entry\n",
    "        if reaction_type == 'reversible':\n",
    "            reversed_entry = {\n",
    "                'id': reaction_id,\n",
    "                'type': 'reversible_reverse',\n",
    "                'pathway': pathway_source,\n",
    "                'substrates': products,\n",
    "                'products': substrates\n",
    "            }\n",
    "            reactions.append(reversed_entry)\n",
    "\n",
    "    return {'relations_info': relations_info, 'reactions': reactions}\n",
    "\n",
    "def write_to_csv(relations_info, reactions, relations_csv, reactions_csv):\n",
    "    # Write relations to CSV\n",
    "    with open(relations_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['starter_ID', 'receiver_ID', 'relation_type', 'subtype_name', 'pathway_source', 'credibility']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for relation in relations_info:\n",
    "            writer.writerow(relation)\n",
    "\n",
    "    # Write reactions to CSV, finding the maximum number of substrates and products\n",
    "    max_subs = max((len(r['substrates']) for r in reactions), default=0)\n",
    "    max_prods = max((len(r['products']) for r in reactions), default=0)\n",
    "    reaction_fieldnames = ['id', 'type', 'pathway'] + \\\n",
    "        [f'substrate{i+1}' for i in range(max_subs)] + \\\n",
    "        [f'product{i+1}' for i in range(max_prods)]\n",
    "    \n",
    "    with open(reactions_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=reaction_fieldnames)\n",
    "        writer.writeheader()\n",
    "        for reaction in reactions:\n",
    "            row = {\n",
    "                'id': reaction['id'],\n",
    "                'type': reaction['type'],\n",
    "                'pathway': reaction['pathway'],\n",
    "            }\n",
    "            row.update({f'substrate{i+1}': sub for i, sub in enumerate(reaction['substrates'])})\n",
    "            row.update({f'product{i+1}': prod for i, prod in enumerate(reaction['products'])})\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Main function to start the process\n",
    "def main():\n",
    "    kgml_directory = 'KGML'\n",
    "    relations_csv = 'pathway_relations.csv'\n",
    "    reactions_csv = 'pathway_reactions.csv'\n",
    "    all_relations_info = []\n",
    "    all_reactions = []\n",
    "\n",
    "    # Process each KGML file and aggregate the information\n",
    "    for filename in os.listdir(kgml_directory):\n",
    "        if filename.endswith('.kgml'):\n",
    "            file_path = os.path.join(kgml_directory, filename)\n",
    "            parsed_data = parse_kgml(file_path)\n",
    "            all_relations_info.extend(parsed_data['relations_info'])\n",
    "            all_reactions.extend(parsed_data['reactions'])\n",
    "\n",
    "    # Write the aggregated information to CSV files\n",
    "    write_to_csv(all_relations_info, all_reactions, relations_csv, reactions_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 8230 unique entity IDs.\n",
      "Prefix: hsa, Count: 6281\n",
      "Prefix: cpd, Count: 1602\n",
      "Prefix: gl:, Count: 205\n",
      "Prefix: pat, Count: 103\n",
      "Prefix: dr:, Count: 37\n",
      "Prefix: und, Count: 1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def extract_unique_ids(relations_csv, reactions_csv):\n",
    "    unique_ids = set()\n",
    "\n",
    "    # Extract from pathway_relations.csv\n",
    "    with open(relations_csv, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            unique_ids.add(row['starter_ID'])\n",
    "            unique_ids.add(row['receiver_ID'])\n",
    "\n",
    "    # Extract from pathway_reactions.csv\n",
    "    with open(reactions_csv, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            for key in row.keys():\n",
    "                if 'substrate' in key or 'product' in key:\n",
    "                    unique_ids.add(row[key])\n",
    "\n",
    "    return unique_ids\n",
    "\n",
    "# Use the function to extract IDs\n",
    "relations_csv = 'pathway_relations.csv'  # Make sure to provide the correct path to your CSV file\n",
    "reactions_csv = 'pathway_reactions.csv'  # Make sure to provide the correct path to your CSV file\n",
    "entity_ids = extract_unique_ids(relations_csv, reactions_csv)\n",
    "\n",
    "# Now you have all unique entity IDs in the `entity_ids` set\n",
    "print(f\"Extracted {len(entity_ids)} unique entity IDs.\")\n",
    "\n",
    "def extract_unique_id_prefixes(unique_ids):\n",
    "    # Extract the first three characters of each ID and count their occurrences\n",
    "    prefix_counts = {}\n",
    "    for kegg_id in unique_ids:\n",
    "        # Extract the first three characters\n",
    "        prefix = kegg_id[:3]\n",
    "        if prefix:\n",
    "            prefix_counts[prefix] = prefix_counts.get(prefix, 0) + 1\n",
    "    return prefix_counts\n",
    "\n",
    "# Process the unique ID prefixes\n",
    "prefix_counts = extract_unique_id_prefixes(entity_ids)\n",
    "\n",
    "# Print the unique prefixes and their counts\n",
    "for prefix, count in prefix_counts.items():\n",
    "    print(f\"Prefix: {prefix}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_undefined_rows(input_csv, output_csv):\n",
    "    # Read the existing CSV file\n",
    "    with open(input_csv, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        rows = [row for row in reader if row['starter_ID'] != 'undefined' and row['receiver_ID'] != 'undefined']\n",
    "\n",
    "    # Write the cleaned data to a new CSV file\n",
    "    with open(output_csv, mode='w', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "# Assuming 'pathway_relations.csv' is the name of your input file\n",
    "input_csv = 'pathway_relations.csv'\n",
    "output_csv = 'pathway_relations_cleaned.csv'\n",
    "\n",
    "# Call the function to remove rows with 'undefined' IDs\n",
    "remove_undefined_rows(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of relations - Train: 69339, Val: 14385, Test: 20312\n",
      "Total number of reactions - Train: 4762, Val: 411, Test: 721\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def load_data(csv_file):\n",
    "    with open(csv_file, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def identify_unique_pathways(data):\n",
    "    unique_pathways = set()\n",
    "    for row in data:\n",
    "        pathways = row['pathway_source'].split(', ')\n",
    "        for pathway in pathways:\n",
    "            unique_pathways.add(pathway)\n",
    "    return list(unique_pathways)\n",
    "\n",
    "def split_pathways(pathways, splits=(0.7, 0.15, 0.15)):\n",
    "    random.shuffle(pathways)\n",
    "    n = len(pathways)\n",
    "    train_end = int(splits[0] * n)\n",
    "    val_end = train_end + int(splits[1] * n)\n",
    "    train, val, test = pathways[:train_end], pathways[train_end:val_end], pathways[val_end:]\n",
    "    return train, val, test\n",
    "\n",
    "def split_data(data, train_pathways, val_pathways, test_pathways):\n",
    "    train, val, test = [], [], []\n",
    "    for row in data:\n",
    "        sources = set(row['pathway_source'].split(', '))\n",
    "        # Priority: test > val > train\n",
    "        if sources & set(test_pathways):\n",
    "            test.append(row)\n",
    "        elif sources & set(val_pathways):\n",
    "            val.append(row)\n",
    "        else:\n",
    "            train.append(row)\n",
    "    return train, val, test\n",
    "\n",
    "def write_data(data, filename, fieldnames):\n",
    "    with open(filename, mode='w', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "relations_data = load_data('pathway_relations_cleaned.csv')\n",
    "reactions_data = load_data('pathway_reactions.csv')\n",
    "\n",
    "unique_pathways = identify_unique_pathways(relations_data + reactions_data)\n",
    "train_pathways, val_pathways, test_pathways = split_pathways(unique_pathways)\n",
    "\n",
    "relations_train, relations_val, relations_test = split_data(relations_data, train_pathways, val_pathways, test_pathways)\n",
    "reactions_train, reactions_val, reactions_test = split_data(reactions_data, train_pathways, val_pathways, test_pathways)\n",
    "\n",
    "write_data(relations_train, 'relations_train.csv', relations_data[0].keys())\n",
    "write_data(relations_val, 'relations_val.csv', relations_data[0].keys())\n",
    "write_data(relations_test, 'relations_test.csv', relations_data[0].keys())\n",
    "\n",
    "write_data(reactions_train, 'reactions_train.csv', reactions_data[0].keys())\n",
    "write_data(reactions_val, 'reactions_val.csv', reactions_data[0].keys())\n",
    "write_data(reactions_test, 'reactions_test.csv', reactions_data[0].keys())\n",
    "\n",
    "print(f\"Total number of relations - Train: {len(relations_train)}, Val: {len(relations_val)}, Test: {len(relations_test)}\")\n",
    "print(f\"Total number of reactions - Train: {len(reactions_train)}, Val: {len(reactions_val)}, Test: {len(reactions_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation IDs not in Train: 403\n",
      "Test IDs not in Train: 1354\n",
      "Validation IDs not in Train: {'hsa:25970', 'hsa:123688', 'hsa:3145', 'hsa:8876', 'hsa:3770', 'hsa:5689', 'hsa:3795', 'hsa:8554', 'hsa:10963', 'hsa:9825', 'hsa:1768', 'hsa:23237', 'hsa:85358', 'hsa:4091', 'hsa:8473', 'hsa:51005', 'hsa:3972', 'hsa:6675', 'hsa:25981', 'hsa:170712', 'hsa:645', 'cpd:C20793', 'hsa:9739', 'hsa:3077', 'hsa:6839', 'hsa:6662', 'hsa:164668', 'hsa:9377', 'hsa:2592', 'gl:G00369', 'cpd:C00017', 'hsa:60436', 'hsa:1347', 'hsa:56681', 'hsa:1262', 'hsa:79709', 'hsa:387893', 'cpd:C05776', 'hsa:79823', 'hsa:60489', 'hsa:2488', 'hsa:23645', 'hsa:100526767', 'hsa:58508', 'hsa:3163', 'hsa:10961', 'hsa:4905', 'hsa:269', 'hsa:433', 'hsa:9623', 'hsa:27018', 'hsa:10130', 'hsa:4512', 'hsa:337876', 'hsa:10113', 'cpd:C01089', 'hsa:54187', 'hsa:4741', 'hsa:9757', 'hsa:1174', 'hsa:1356', 'hsa:2584', 'hsa:6419', 'hsa:165324', 'hsa:7067', 'hsa:1340', 'hsa:25956', 'hsa:9765', 'hsa:1329', 'hsa:53354', 'hsa:4513', 'hsa:60496', 'hsa:2492', 'hsa:54480', 'hsa:5684', 'hsa:5683', 'hsa:143471', 'hsa:3434', 'hsa:84444', 'hsa:4747', 'hsa:8985', 'hsa:181', 'hsa:10483', 'hsa:5238', 'hsa:64332', 'hsa:2585', 'cpd:C02515', 'hsa:2145', 'hsa:3547', 'hsa:1352', 'hsa:200316', 'hsa:27005', 'hsa:405753', 'cpd:C01413', 'hsa:1260', 'hsa:8085', 'path:map00643', 'hsa:3768', 'hsa:5686', 'hsa:1355', 'hsa:3052', 'hsa:4351', 'hsa:10484', 'hsa:1118', 'hsa:23190', 'hsa:85363', 'hsa:1339', 'cpd:C20935', 'hsa:55577', 'hsa:5803', 'hsa:4066', 'hsa:26585', 'hsa:5372', 'hsa:212', 'hsa:57761', 'hsa:8790', 'hsa:148738', 'hsa:2696', 'hsa:7376', 'cpd:C20792', 'hsa:23067', 'hsa:5020', 'hsa:5948', 'hsa:2899', 'hsa:11213', 'hsa:3028', 'hsa:1445', 'hsa:85007', 'hsa:55790', 'hsa:23127', 'hsa:125965', 'hsa:3337', 'hsa:2901', 'hsa:79852', 'hsa:10157', 'hsa:201625', 'hsa:10053', 'hsa:29072', 'hsa:2615', 'hsa:64754', 'hsa:83852', 'hsa:196', 'hsa:8115', 'hsa:29926', 'hsa:79723', 'hsa:358', 'hsa:5352', 'hsa:5691', 'cpd:C20300', 'hsa:11105', 'hsa:55567', 'hsa:8701', 'hsa:79813', 'hsa:9229', 'cpd:C01829', 'hsa:341947', 'hsa:5348', 'hsa:10636', 'hsa:1770', 'hsa:5694', 'hsa:66008', 'hsa:4297', 'hsa:10919', 'cpd:C07535', 'hsa:55968', 'hsa:140838', 'hsa:57103', 'hsa:684', 'hsa:8905', 'hsa:1327', 'hsa:253152', 'hsa:4514', 'hsa:53905', 'hsa:55454', 'hsa:79646', 'hsa:51035', 'hsa:4756', 'hsa:150572', 'hsa:7264', 'hsa:10452', 'hsa:100134444', 'hsa:6751', 'cpd:C06696', 'hsa:11108', 'hsa:2001', 'hsa:2331', 'hsa:4681', 'hsa:122876', 'hsa:57498', 'hsa:10007', 'hsa:5693', 'hsa:196385', 'hsa:133522', 'hsa:7038', 'hsa:23035', 'hsa:2762', 'hsa:5621', 'hsa:91373', 'hsa:5909', 'hsa:7050', 'hsa:5034', 'hsa:51738', 'hsa:146754', 'hsa:127602', 'hsa:260425', 'hsa:5688', 'hsa:23239', 'hsa:5687', 'hsa:1345', 'hsa:10021', 'hsa:162', 'hsa:8843', 'hsa:26037', 'hsa:27198', 'hsa:9863', 'hsa:4092', 'hsa:3588', 'hsa:7415', 'hsa:1351', 'hsa:2693', 'hsa:64411', 'hsa:54714', 'hsa:889', 'hsa:3646', 'hsa:3761', 'hsa:9241', 'hsa:9167', 'hsa:23435', 'hsa:3587', 'hsa:200315', 'hsa:2235', 'hsa:5690', 'hsa:80896', 'hsa:4515', 'path:map00311', 'hsa:210', 'hsa:258010', 'hsa:27350', 'hsa:5664', 'hsa:5334', 'hsa:7434', 'cpd:C07295', 'hsa:10724', 'cpd:C00473', 'hsa:1346', 'cpd:C00042', 'hsa:25974', 'hsa:51128', 'hsa:83544', 'cpd:C07557', 'hsa:57568', 'hsa:5695', 'hsa:64446', 'hsa:79586', 'hsa:7226', 'hsa:7390', 'hsa:211', 'hsa:9372', 'hsa:120892', 'hsa:100913187', 'hsa:2897', 'hsa:1371', 'hsa:56950', 'hsa:2898', 'cpd:C04623', 'hsa:64388', 'hsa:29941', 'hsa:79643', 'hsa:56670', 'hsa:1769', 'path:hsa00524', 'hsa:5351', 'hsa:51111', 'hsa:132789', 'hsa:5682', 'cpd:C16514', 'hsa:9415', 'hsa:22941', 'hsa:9131', 'cpd:C00186', 'hsa:27019', 'hsa:79717', 'hsa:25942', 'hsa:84701', 'hsa:93166', 'hsa:57412', 'hsa:2867', 'hsa:54904', 'hsa:644', 'hsa:1979', 'hsa:4744', 'path:map00540', 'hsa:7802', 'hsa:8875', 'hsa:5692', 'hsa:8646', 'path:map00523', 'hsa:6647', 'dr:D07445', 'hsa:4602', 'hsa:8907', 'hsa:81567', 'hsa:8906', 'hsa:54822', 'hsa:5611', 'hsa:439996', 'hsa:55907', 'hsa:80347', 'hsa:2900', 'hsa:5685', 'hsa:4025', 'hsa:1447', 'hsa:10019', 'hsa:80700', 'hsa:1350', 'hsa:10782', 'hsa:10802', 'hsa:164', 'hsa:55666', 'hsa:5795', 'hsa:2395', 'hsa:1337', 'hsa:22872', 'hsa:50944', 'hsa:102', 'hsa:9732', 'hsa:7389', 'hsa:27159', 'hsa:10468', 'hsa:10637', 'hsa:80146', 'hsa:1261', 'hsa:56171', 'hsa:2582', 'hsa:4052', 'hsa:2014', 'hsa:5973', 'hsa:6755', 'hsa:51466', 'hsa:10427', 'path:hsa00780', 'hsa:55904', 'hsa:1349', 'hsa:9871', 'hsa:50506', 'hsa:197258', 'hsa:55870', 'hsa:285704', 'hsa:56979', 'hsa:9500', 'cpd:C16515', 'hsa:91543', 'hsa:64324', 'hsa:7044', 'hsa:100532736', 'hsa:338442', 'hsa:84134', 'hsa:1410', 'hsa:130340', 'hsa:140564', 'hsa:57679', 'hsa:5498', 'hsa:8632', 'hsa:9582', 'hsa:7036', 'hsa:170589', 'hsa:10126', 'hsa:7466', 'hsa:7468', 'hsa:7270', 'hsa:3906', 'hsa:8424', 'hsa:7353', 'hsa:9632', 'hsa:9762', 'hsa:124044', 'hsa:7799', 'hsa:64841', 'hsa:10020', 'hsa:7068', 'hsa:84787', 'hsa:56605', 'hsa:375387', 'hsa:4145', 'hsa:3938', 'hsa:5373', 'hsa:8458', 'hsa:7993', 'hsa:51652', 'cpd:C01060', 'hsa:29925', 'hsa:22856', 'hsa:432', 'hsa:9869', 'hsa:1767', 'hsa:7432', 'hsa:80025', 'hsa:60490', 'cpd:C00064', 'hsa:56963', 'hsa:10231', 'hsa:9001', 'hsa:610'}\n",
      "Test IDs not in Train: {'hsa:441608', 'hsa:2797', 'hsa:6753', 'hsa:147746', 'hsa:253639', 'hsa:29992', 'hsa:119678', 'hsa:388569', 'hsa:5025', 'hsa:85569', 'hsa:79339', 'hsa:339318', 'hsa:3814', 'hsa:219453', 'hsa:122042', 'hsa:7755', 'hsa:254973', 'hsa:100289635', 'hsa:79973', 'hsa:390201', 'hsa:390083', 'hsa:26538', 'hsa:6019', 'hsa:1347', 'hsa:83988', 'hsa:2488', 'hsa:100289678', 'hsa:134083', 'hsa:26333', 'hsa:338751', 'hsa:283189', 'hsa:119772', 'hsa:682', 'hsa:286365', 'hsa:390155', 'hsa:64005', 'hsa:2587', 'hsa:7710', 'hsa:122742', 'hsa:6940', 'hsa:26339', 'hsa:1948', 'cpd:C16512', 'hsa:2922', 'hsa:390264', 'hsa:138804', 'hsa:1329', 'hsa:388523', 'hsa:4542', 'hsa:120776', 'hsa:255725', 'hsa:4747', 'hsa:654254', 'hsa:29990', 'hsa:390079', 'hsa:728927', 'hsa:81341', 'hsa:140885', 'hsa:57223', 'hsa:9422', 'hsa:127066', 'hsa:7932', 'hsa:341416', 'hsa:10911', 'cpd:C12270', 'hsa:10520', 'hsa:4992', 'hsa:55568', 'hsa:5365', 'hsa:2591', 'hsa:7433', 'hsa:155054', 'hsa:2241', 'hsa:9723', 'hsa:107987545', 'hsa:342892', 'hsa:199704', 'path:map01053', 'hsa:257313', 'hsa:84671', 'hsa:390113', 'hsa:57786', 'hsa:81392', 'hsa:7711', 'hsa:27153', 'hsa:26531', 'hsa:117608', 'hsa:390441', 'hsa:9411', 'hsa:212', 'hsa:2696', 'hsa:4008', 'hsa:2741', 'hsa:2899', 'hsa:388559', 'hsa:51052', 'cpd:C01319', 'hsa:170960', 'hsa:677', 'hsa:347344', 'hsa:342909', 'hsa:58492', 'hsa:121275', 'hsa:125965', 'hsa:442117', 'cpd:C14573', 'hsa:392390', 'hsa:27232', 'hsa:137970', 'hsa:10022', 'hsa:8387', 'hsa:126070', 'hsa:26290', 'hsa:7553', 'hsa:4159', 'hsa:4641', 'hsa:120796', 'hsa:90576', 'hsa:7638', 'hsa:81470', 'hsa:2044', 'hsa:255061', 'hsa:391190', 'hsa:10461', 'hsa:341947', 'path:hsa00920', 'cpd:C07434', 'hsa:26740', 'hsa:10795', 'hsa:168417', 'cpd:C07535', 'hsa:79077', 'hsa:1949', 'cpd:C11371', 'hsa:51179', 'hsa:4640', 'hsa:84449', 'hsa:81469', 'hsa:440519', 'hsa:390162', 'hsa:390883', 'hsa:84527', 'hsa:1841', 'hsa:92595', 'hsa:26735', 'hsa:23743', 'hsa:9248', 'hsa:4922', 'hsa:4829', 'hsa:7561', 'hsa:9831', 'hsa:282763', 'path:map01059', 'hsa:126541', 'hsa:84466', 'hsa:134526', 'hsa:219464', 'hsa:343171', 'hsa:7009', 'hsa:147837', 'hsa:54896', 'hsa:8386', 'hsa:11226', 'hsa:162239', 'hsa:79744', 'hsa:8427', 'hsa:7301', 'hsa:9038', 'hsa:1135', 'hsa:80143', 'hsa:388558', 'hsa:51738', 'hsa:55957', 'hsa:7224', 'hsa:254786', 'hsa:875', 'hsa:403244', 'hsa:11214', 'hsa:10780', 'cpd:C11042', 'hsa:57335', 'hsa:390261', 'hsa:6506', 'hsa:390648', 'hsa:504190', 'hsa:390195', 'hsa:59', 'hsa:390038', 'hsa:23166', 'hsa:390168', 'hsa:441639', 'hsa:150681', 'hsa:163223', 'hsa:27300', 'hsa:219958', 'hsa:284307', 'hsa:3587', 'hsa:5746', 'hsa:100129543', 'hsa:390260', 'hsa:219873', 'hsa:390649', 'hsa:391107', 'hsa:390439', 'hsa:5048', 'hsa:1759', 'cpd:C02166', 'cpd:C00049', 'hsa:64221', 'hsa:124907837', 'hsa:1346', 'hsa:594857', 'hsa:2050', 'cpd:C07557', 'hsa:80264', 'hsa:392309', 'hsa:728957', 'hsa:220992', 'hsa:390191', 'hsa:219954', 'hsa:390433', 'hsa:388761', 'hsa:26493', 'cpd:C00019', 'hsa:390265', 'hsa:219429', 'hsa:2897', 'hsa:219493', 'hsa:442185', 'hsa:148254', 'hsa:127062', 'hsa:2831', 'hsa:26534', 'hsa:5645', 'hsa:23200', 'hsa:390190', 'hsa:22835', 'hsa:57152', 'hsa:348180', 'hsa:389090', 'hsa:79290', 'hsa:283093', 'hsa:199692', 'hsa:10172', 'hsa:79891', 'hsa:390084', 'hsa:55930', 'hsa:51385', 'hsa:7565', 'hsa:83551', 'hsa:2832', 'hsa:56920', 'hsa:127077', 'hsa:84701', 'hsa:219959', 'hsa:504191', 'hsa:129521', 'hsa:29984', 'hsa:144124', 'hsa:163227', 'hsa:91584', 'hsa:3060', 'cpd:C06916', 'hsa:168374', 'cpd:C16453', 'hsa:5032', 'hsa:84245', 'hsa:1138', 'hsa:84765', 'hsa:126231', 'cpd:C00696', 'hsa:81300', 'hsa:83744', 'hsa:2739', 'hsa:722', 'hsa:730291', 'hsa:121364', 'hsa:403274', 'hsa:7562', 'hsa:8392', 'hsa:9287', 'hsa:55113', 'hsa:388567', 'hsa:120787', 'hsa:1723', 'hsa:93474', 'hsa:117579', 'hsa:59350', 'hsa:133121', 'hsa:445329', 'hsa:119749', 'hsa:2692', 'hsa:79295', 'hsa:127059', 'hsa:390054', 'hsa:90987', 'hsa:79346', 'hsa:26696', 'hsa:219956', 'hsa:351', 'hsa:11255', 'hsa:442194', 'hsa:283617', 'hsa:81318', 'hsa:51710', 'hsa:102', 'hsa:90338', 'hsa:83605', 'hsa:26245', 'hsa:374928', 'hsa:7712', 'hsa:6013', 'hsa:390081', 'hsa:6754', 'hsa:441933', 'hsa:57541', 'hsa:26052', 'hsa:79957', 'hsa:125962', 'hsa:29958', 'hsa:5199', 'hsa:121129', 'hsa:126375', 'hsa:138802', 'hsa:7743', 'hsa:79345', 'hsa:341276', 'hsa:84914', 'hsa:148103', 'hsa:9247', 'hsa:90353', 'hsa:387129', 'hsa:6430', 'hsa:119764', 'hsa:1947', 'hsa:10874', 'hsa:285267', 'hsa:100131827', 'hsa:7341', 'hsa:5367', 'hsa:84874', 'hsa:56242', 'hsa:65251', 'hsa:7549', 'hsa:81309', 'hsa:126068', 'hsa:94039', 'hsa:79788', 'hsa:219986', 'hsa:3001', 'cpd:C16452', 'hsa:79324', 'hsa:374879', 'hsa:390321', 'hsa:81605', 'hsa:126295', 'hsa:79310', 'hsa:93134', 'hsa:390144', 'hsa:391195', 'hsa:345462', 'hsa:164091', 'hsa:9245', 'hsa:4143', 'hsa:5364', 'hsa:219960', 'hsa:6866', 'hsa:100287226', 'hsa:390059', 'hsa:97', 'hsa:23382', 'hsa:26060', 'hsa:53', 'hsa:284306', 'hsa:282890', 'hsa:9860', 'hsa:5539', 'hsa:162967', 'hsa:56896', 'hsa:163051', 'hsa:390437', 'hsa:5744', 'hsa:729759', 'hsa:57547', 'hsa:55584', 'hsa:57474', 'hsa:6431', 'hsa:645', 'hsa:79501', 'hsa:391112', 'hsa:1325', 'hsa:9377', 'hsa:7596', 'hsa:55808', 'hsa:55713', 'hsa:219417', 'hsa:8883', 'hsa:10798', 'hsa:90233', 'hsa:79139', 'hsa:55576', 'hsa:55671', 'hsa:26692', 'hsa:119692', 'hsa:2691', 'hsa:4512', 'hsa:119687', 'hsa:58478', 'hsa:127074', 'hsa:10505', 'hsa:1757', 'hsa:8623', 'hsa:84924', 'hsa:64087', 'hsa:84448', 'hsa:80818', 'hsa:403277', 'hsa:1260', 'hsa:10512', 'hsa:7988', 'hsa:23620', 'hsa:343170', 'hsa:23235', 'hsa:390082', 'hsa:81285', 'hsa:26689', 'hsa:5368', 'hsa:114805', 'hsa:90321', 'hsa:11112', 'hsa:81168', 'cpd:C01598', 'hsa:54925', 'hsa:2834', 'hsa:4828', 'hsa:54922', 'hsa:3028', 'hsa:2045', 'hsa:3062', 'hsa:10424', 'hsa:4295', 'hsa:283871', 'hsa:2042', 'hsa:4605', 'hsa:55552', 'hsa:219479', 'hsa:7425', 'hsa:10857', 'hsa:8001', 'hsa:132660', 'hsa:2837', 'hsa:6585', 'hsa:338440', 'hsa:90226', 'hsa:7594', 'hsa:7568', 'hsa:79544', 'hsa:100529215', 'hsa:162972', 'hsa:81127', 'hsa:26529', 'cpd:C00075', 'hsa:401667', 'hsa:399967', 'hsa:219982', 'hsa:2642', 'hsa:152687', 'hsa:401993', 'hsa:4514', 'hsa:390075', 'hsa:80095', 'hsa:90249', 'hsa:3483', 'hsa:283297', 'hsa:8484', 'hsa:23654', 'hsa:81697', 'hsa:2041', 'hsa:391121', 'hsa:2894', 'cpd:C00046', 'hsa:146540', 'hsa:119695', 'hsa:58500', 'hsa:219869', 'hsa:340385', 'hsa:4666', 'hsa:346171', 'hsa:57343', 'hsa:254879', 'hsa:10507', 'hsa:442191', 'hsa:25799', 'hsa:127608', 'hsa:286410', 'hsa:7761', 'hsa:26974', 'hsa:135924', 'hsa:5051', 'hsa:283869', 'hsa:122740', 'hsa:219473', 'hsa:7554', 'hsa:130075', 'hsa:79695', 'hsa:100169851', 'hsa:127064', 'hsa:26189', 'hsa:113835', 'hsa:6863', 'hsa:148268', 'hsa:390432', 'hsa:81931', 'cpd:C07151', 'hsa:6612', 'hsa:7592', 'hsa:2796', 'hsa:26476', 'hsa:5928', 'hsa:171392', 'hsa:162966', 'hsa:889', 'hsa:26539', 'hsa:9167', 'hsa:23435', 'hsa:390174', 'cpd:C05113', 'hsa:128371', 'hsa:653166', 'hsa:387082', 'hsa:1269', 'hsa:340980', 'hsa:10313', 'hsa:196527', 'hsa:81327', 'hsa:29071', 'hsa:389114', 'hsa:80778', 'hsa:5284', 'hsa:390152', 'hsa:2743', 'hsa:390275', 'hsa:353355', 'hsa:7941', 'hsa:362', 'cpd:C00001', 'hsa:1142', 'hsa:63934', 'hsa:146434', 'cpd:C13624', 'hsa:284383', 'hsa:504189', 'hsa:211', 'hsa:346528', 'hsa:147929', 'hsa:51588', 'hsa:6426', 'hsa:90075', 'hsa:2859', 'hsa:392138', 'hsa:390036', 'hsa:10794', 'cpd:C04623', 'hsa:7767', 'hsa:138883', 'hsa:2742', 'hsa:7625', 'hsa:138882', 'hsa:4991', 'hsa:283694', 'hsa:402135', 'hsa:204851', 'hsa:400713', 'hsa:26212', 'hsa:219981', 'hsa:6818', 'hsa:387748', 'hsa:284323', 'hsa:4326', 'cpd:C16511', 'hsa:79767', 'hsa:391109', 'hsa:163081', 'hsa:199777', 'cpd:C02737', 'hsa:140612', 'hsa:6647', 'hsa:5627', 'hsa:126370', 'path:hsa00310', 'hsa:120586', 'hsa:7768', 'hsa:57573', 'cpd:C11906', 'hsa:219965', 'hsa:5697', 'hsa:7582', 'hsa:26664', 'hsa:1145', 'hsa:54910', 'path:map00521', 'hsa:441669', 'hsa:139735', 'hsa:391189', 'hsa:4986', 'hsa:196335', 'hsa:388536', 'hsa:170958', 'hsa:4643', 'hsa:102724560', 'hsa:1261', 'hsa:5026', 'hsa:5787', 'hsa:2589', 'hsa:7673', 'hsa:138803', 'hsa:440077', 'hsa:319100', 'hsa:26683', 'hsa:144125', 'hsa:81282', 'hsa:1140', 'hsa:128372', 'hsa:56913', 'hsa:349075', 'hsa:90317', 'hsa:23621', 'hsa:1146', 'hsa:79230', 'hsa:148266', 'hsa:51761', 'hsa:28996', 'hsa:25888', 'hsa:1875', 'hsa:81458', 'hsa:57452', 'hsa:7637', 'hsa:26533', 'hsa:90649', 'hsa:170589', 'hsa:343173', 'hsa:338376', 'hsa:27334', 'cpd:C08150', 'hsa:347168', 'hsa:7068', 'hsa:7639', 'hsa:51427', 'hsa:5362', 'hsa:219431', 'hsa:55312', 'hsa:84911', 'hsa:148213', 'cpd:C03690', 'hsa:122748', 'hsa:148198', 'cpd:C00015', 'hsa:284309', 'hsa:7432', 'hsa:286362', 'hsa:25825', 'hsa:7772', 'hsa:390892', 'hsa:100133941', 'hsa:374378', 'hsa:401665', 'hsa:10886', 'hsa:147741', 'hsa:4323', 'hsa:117178', 'hsa:79862', 'hsa:392391', 'hsa:26188', 'hsa:256148', 'cpd:C01516', 'hsa:390063', 'hsa:390061', 'hsa:8829', 'hsa:440153', 'hsa:101060200', 'hsa:56656', 'hsa:339559', 'hsa:192134', 'cpd:C06314', 'hsa:170712', 'hsa:79818', 'hsa:158131', 'hsa:10610', 'hsa:284161', 'hsa:134864', 'hsa:64409', 'hsa:6799', 'hsa:64218', 'hsa:283162', 'hsa:1635', 'hsa:9310', 'hsa:219447', 'hsa:26152', 'hsa:3394', 'hsa:63917', 'hsa:3983', 'hsa:84539', 'path:map00966', 'hsa:26762', 'hsa:9970', 'hsa:680', 'hsa:26341', 'hsa:115509', 'hsa:85315', 'hsa:79132', 'hsa:6613', 'hsa:79623', 'hsa:22885', 'hsa:285659', 'hsa:128366', 'hsa:100996758', 'hsa:219469', 'hsa:390037', 'hsa:7067', 'hsa:1340', 'hsa:284370', 'hsa:8693', 'cpd:C00099', 'cpd:C15891', 'hsa:125963', 'hsa:387521', 'hsa:255403', 'hsa:57232', 'hsa:1241', 'hsa:338662', 'hsa:219437', 'hsa:10316', 'hsa:7694', 'hsa:81607', 'hsa:203859', 'hsa:121130', 'cpd:C12272', 'hsa:338675', 'hsa:125958', 'hsa:390157', 'hsa:163131', 'hsa:353088', 'hsa:442186', 'hsa:125919', 'hsa:283111', 'hsa:26648', 'hsa:51251', 'hsa:127623', 'hsa:283160', 'hsa:390151', 'hsa:4324', 'hsa:4887', 'cpd:C20935', 'path:map00522', 'hsa:7556', 'hsa:100131017', 'hsa:219482', 'hsa:127069', 'hsa:29968', 'hsa:26227', 'hsa:4644', 'hsa:346525', 'hsa:7376', 'cpd:C00607', 'hsa:403282', 'hsa:10873', 'hsa:79898', 'hsa:81328', 'hsa:57522', 'hsa:7728', 'hsa:348327', 'hsa:3141', 'cpd:C11150', 'hsa:7571', 'hsa:223117', 'hsa:79088', 'hsa:84465', 'hsa:196', 'hsa:5723', 'hsa:136051', 'hsa:4642', 'hsa:51074', 'hsa:66004', 'hsa:163255', 'hsa:120065', 'hsa:26496', 'hsa:341152', 'hsa:10326', 'hsa:56832', 'cpd:C01829', 'hsa:286046', 'hsa:5049', 'hsa:7771', 'hsa:4144', 'hsa:284433', 'hsa:197257', 'hsa:1327', 'hsa:80032', 'hsa:390323', 'hsa:7581', 'hsa:84436', 'hsa:147660', 'hsa:128360', 'hsa:54753', 'hsa:112268384', 'hsa:344787', 'hsa:81466', 'hsa:391191', 'hsa:143502', 'hsa:84868', 'hsa:284371', 'hsa:92285', 'hsa:7559', 'hsa:84634', 'hsa:7733', 'hsa:390429', 'hsa:134860', 'hsa:30832', 'hsa:219484', 'hsa:98', 'hsa:57101', 'hsa:341568', 'hsa:26707', 'cpd:C00506', 'hsa:6428', 'hsa:56922', 'hsa:2650', 'hsa:27289', 'hsa:10893', 'cpd:C04598', 'hsa:390980', 'hsa:401992', 'hsa:9934', 'hsa:341418', 'hsa:10838', 'hsa:112609', 'hsa:390066', 'hsa:393046', 'hsa:390058', 'hsa:147949', 'hsa:4987', 'hsa:688', 'hsa:26211', 'hsa:549', 'hsa:442319', 'hsa:55762', 'hsa:10154', 'hsa:285220', 'hsa:59348', 'hsa:110116772', 'hsa:55422', 'hsa:65243', 'hsa:390431', 'hsa:391192', 'hsa:26716', 'hsa:147945', 'hsa:344838', 'hsa:8383', 'hsa:8754', 'hsa:860', 'hsa:163050', 'hsa:387522', 'hsa:3467', 'hsa:442184', 'cpd:C04227', 'hsa:286530', 'hsa:1808', 'hsa:113091', 'hsa:63982', 'hsa:26497', 'hsa:27304', 'hsa:1163', 'hsa:990', 'hsa:390326', 'hsa:2898', 'hsa:7695', 'hsa:440515', 'hsa:219858', 'hsa:138799', 'hsa:79724', 'hsa:114786', 'cpd:C16514', 'cpd:C15890', 'hsa:9855', 'hsa:403253', 'hsa:219870', 'hsa:441234', 'hsa:59340', 'hsa:2051', 'hsa:26737', 'hsa:163071', 'hsa:347468', 'cpd:C07909', 'hsa:441308', 'hsa:90594', 'hsa:26686', 'hsa:7587', 'hsa:84109', 'hsa:391211', 'hsa:81399', 'hsa:1874', 'hsa:51454', 'hsa:4995', 'hsa:728819', 'hsa:11235', 'hsa:401994', 'hsa:54941', 'hsa:347148', 'hsa:81442', 'hsa:10768', 'hsa:219438', 'hsa:64111', 'hsa:163087', 'hsa:9353', 'hsa:2047', 'hsa:100528030', 'hsa:146198', 'hsa:81797', 'hsa:168391', 'hsa:8521', 'hsa:162998', 'hsa:53829', 'hsa:7769', 'hsa:4161', 'hsa:374899', 'hsa:219875', 'hsa:2043', 'hsa:2900', 'hsa:6188', 'hsa:51268', 'hsa:403273', 'hsa:400720', 'hsa:5050', 'hsa:339327', 'hsa:390077', 'hsa:79153', 'hsa:342926', 'hsa:2653', 'hsa:1350', 'hsa:119694', 'hsa:391114', 'hsa:7748', 'hsa:390067', 'hsa:81448', 'hsa:5795', 'hsa:80110', 'hsa:23464', 'hsa:4240', 'path:map00402', 'hsa:155061', 'path:map01058', 'hsa:90333', 'hsa:1503', 'hsa:391196', 'hsa:120066', 'hsa:730051', 'hsa:4199', 'hsa:402317', 'hsa:23355', 'hsa:10929', 'hsa:282775', 'hsa:143503', 'hsa:6755', 'hsa:730087', 'hsa:150094', 'hsa:114026', 'hsa:284459', 'hsa:3640', 'hsa:401666', 'hsa:1349', 'hsa:130574', 'hsa:56474', 'hsa:390072', 'cpd:C16515', 'hsa:81856', 'hsa:2046', 'hsa:686', 'hsa:128368', 'hsa:390197', 'hsa:219487', 'hsa:8811', 'hsa:5630', 'hsa:147686', 'hsa:91661', 'hsa:79490', 'hsa:9901', 'hsa:119682', 'hsa:100129842', 'cpd:C19610', 'hsa:148156', 'hsa:147657', 'hsa:10189', 'hsa:79175', 'hsa:160065', 'hsa:6092', 'hsa:8540', 'hsa:91975', 'hsa:147923', 'hsa:11227', 'hsa:9534', 'hsa:7652', 'hsa:256892', 'hsa:6817', 'cpd:C05951', 'hsa:7700', 'hsa:55769', 'hsa:7692', 'hsa:284532', 'hsa:256933', 'hsa:678', 'hsa:162962', 'hsa:254783', 'hsa:56963', 'hsa:127396', 'hsa:138881', 'hsa:635', 'hsa:10793', 'cpd:C00483', 'hsa:5361', 'hsa:105369274', 'hsa:125893', 'hsa:7752', 'cpd:C14240', 'hsa:4994', 'hsa:201514', 'hsa:114131', 'hsa:143496', 'hsa:346517', 'hsa:219952', 'hsa:284349', 'cpd:C06865', 'hsa:26595', 'hsa:120775', 'hsa:135946', 'hsa:148206', 'hsa:5646', 'hsa:119679', 'hsa:219436', 'hsa:3972', 'hsa:26659', 'hsa:138805', 'hsa:163059', 'hsa:50614', 'hsa:162963', 'hsa:81099', 'hsa:8590', 'hsa:1262', 'hsa:399968', 'hsa:285676', 'hsa:5998', 'hsa:165829', 'hsa:26246', 'hsa:80763', 'hsa:322', 'hsa:102724428', 'hsa:79482', 'hsa:4741', 'hsa:55593', 'hsa:5031', 'hsa:8578', 'hsa:8683', 'hsa:283092', 'hsa:6432', 'hsa:81472', 'hsa:390199', 'hsa:4513', 'hsa:2492', 'hsa:10371', 'hsa:4889', 'hsa:122539214', 'hsa:170959', 'hsa:130576', 'hsa:7525', 'hsa:139420', 'hsa:219968', 'hsa:390271', 'hsa:7567', 'hsa:119765', 'hsa:392392', 'hsa:285268', 'hsa:146542', 'hsa:390445', 'cpd:C06697', 'hsa:81061', 'hsa:84503', 'hsa:64106', 'hsa:169841', 'hsa:50636', 'hsa:1339', 'hsa:256144', 'hsa:4993', 'hsa:162993', 'hsa:8388', 'hsa:7200', 'hsa:23250', 'cpd:C05952', 'hsa:81888', 'hsa:23538', 'hsa:56923', 'hsa:81050', 'hsa:7617', 'hsa:2847', 'hsa:91750', 'hsa:1654', 'hsa:390064', 'hsa:54363', 'hsa:8482', 'hsa:79317', 'hsa:51289', 'hsa:219957', 'hsa:5020', 'hsa:1144', 'hsa:6405', 'hsa:117248', 'hsa:91937', 'hsa:286075', 'hsa:10396', 'hsa:79296', 'hsa:27034', 'hsa:26658', 'hsa:147687', 'hsa:2908', 'hsa:725', 'hsa:2901', 'hsa:57615', 'hsa:388566', 'hsa:127385', 'hsa:148203', 'hsa:7770', 'hsa:338755', 'hsa:4507', 'hsa:127068', 'hsa:79658', 'hsa:26219', 'hsa:26693', 'hsa:441670', 'hsa:9127', 'hsa:124538', 'hsa:191', 'hsa:2242', 'hsa:79334', 'hsa:79473', 'hsa:3061', 'hsa:79813', 'hsa:390142', 'cpd:C15995', 'hsa:8390', 'hsa:390078', 'hsa:26149', 'hsa:10919', 'hsa:10061', 'hsa:57142', 'hsa:92283', 'hsa:684', 'hsa:5531', 'hsa:10114', 'hsa:89790', 'hsa:9392', 'hsa:390181', 'hsa:4756', 'hsa:390882', 'hsa:55754', 'hsa:403284', 'hsa:4160', 'hsa:81696', 'hsa:51809', 'hsa:10452', 'path:map00404', 'hsa:54811', 'hsa:6751', 'hsa:135948', 'hsa:390167', 'hsa:122876', 'cpd:C00398', 'hsa:7223', 'hsa:403278', 'hsa:163049', 'hsa:7738', 'hsa:390154', 'hsa:51301', 'hsa:9340', 'hsa:1134', 'hsa:6427', 'hsa:7699', 'hsa:22869', 'hsa:26687', 'hsa:343406', 'hsa:158431', 'hsa:7678', 'hsa:126017', 'hsa:80308', 'hsa:343563', 'cpd:C07020', 'hsa:4430', 'hsa:1345', 'hsa:3029', 'hsa:26338', 'hsa:7757', 'cpd:C03582', 'hsa:729747', 'hsa:3588', 'hsa:6091', 'hsa:1351', 'hsa:2693', 'hsa:7569', 'hsa:343169', 'hsa:283446', 'hsa:23380', 'hsa:5168', 'hsa:79541', 'hsa:7644', 'hsa:390327', 'hsa:6429', 'hsa:5664', 'hsa:55256', 'hsa:10308', 'hsa:57715', 'hsa:147948', 'hsa:7434', 'hsa:401427', 'hsa:51083', 'hsa:2895', 'hsa:338674', 'hsa:5729', 'hsa:57053', 'hsa:286826', 'hsa:4200', 'hsa:90827', 'hsa:389668', 'hsa:57209', 'hsa:343702', 'hsa:390436', 'hsa:57693', 'cpd:C00245', 'hsa:91120', 'hsa:5644', 'cpd:C01120', 'cpd:C00037', 'hsa:219874', 'hsa:54807', 'hsa:5540', 'hsa:432355', 'hsa:7349', 'hsa:7539', 'hsa:5300', 'hsa:1164', 'hsa:390148', 'hsa:79549', 'hsa:390093', 'hsa:442361', 'hsa:2590', 'hsa:26532', 'hsa:121274', 'hsa:10224', 'hsa:129607', 'hsa:392376', 'hsa:342908', 'hsa:7773', 'hsa:90592', 'hsa:4744', 'path:map00901', 'hsa:339403', 'hsa:1053', 'hsa:219699', 'hsa:374900', 'hsa:121601', 'hsa:55423', 'hsa:388561', 'hsa:55659', 'hsa:162655', 'hsa:7643', 'hsa:57677', 'hsa:390927', 'hsa:169270', 'hsa:282770', 'hsa:2049', 'hsa:9380', 'hsa:403257', 'hsa:5179', 'hsa:7691', 'hsa:219477', 'hsa:2862', 'hsa:55900', 'hsa:147658', 'hsa:8620', 'hsa:284521', 'hsa:26494', 'hsa:55558', 'hsa:115024', 'hsa:2305', 'hsa:6732', 'hsa:102723532', 'hsa:1337', 'hsa:283365', 'hsa:197320', 'hsa:391194', 'hsa:5449', 'hsa:284406', 'hsa:27430', 'hsa:7551', 'hsa:343172', 'hsa:147694', 'hsa:26530', 'hsa:119774', 'hsa:2798', 'hsa:340252', 'hsa:8633', 'hsa:219983', 'hsa:7766', 'hsa:115196', 'cpd:C00073', 'hsa:128367', 'hsa:64386', 'hsa:84134', 'hsa:26248', 'hsa:57679', 'hsa:403239', 'hsa:7633', 'hsa:84775', 'hsa:7730', 'hsa:255043', 'hsa:390442', 'hsa:219428', 'hsa:284390', 'hsa:55786', 'hsa:9935', 'hsa:135941', 'hsa:2048', 'hsa:57493', 'hsa:219432', 'hsa:120793', 'hsa:54852', 'hsa:55349', 'hsa:347169', 'hsa:390538', 'hsa:641339', 'hsa:4645', 'hsa:7869', 'hsa:3712', 'hsa:283159', 'hsa:51276', 'hsa:7574', 'hsa:7576', 'hsa:341799', 'hsa:9668', 'hsa:10888', 'hsa:219865', 'hsa:57711', 'hsa:25791', 'hsa:256051', 'hsa:10509', 'hsa:392133', 'hsa:91664', 'hsa:219749'}\n"
     ]
    }
   ],
   "source": [
    "def load_ids_from_csv(csv_file):\n",
    "    unique_ids = set()\n",
    "    with open(csv_file, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            unique_ids.add(row['starter_ID'])\n",
    "            unique_ids.add(row['receiver_ID'])\n",
    "    return unique_ids\n",
    "\n",
    "def check_id_coverage(train_csv, val_csv, test_csv):\n",
    "    train_ids = load_ids_from_csv(train_csv)\n",
    "    val_ids = load_ids_from_csv(val_csv)\n",
    "    test_ids = load_ids_from_csv(test_csv)\n",
    "\n",
    "    val_not_in_train = val_ids - train_ids\n",
    "    test_not_in_train = test_ids - train_ids\n",
    "\n",
    "    print(f\"Validation IDs not in Train: {len(val_not_in_train)}\")\n",
    "    print(f\"Test IDs not in Train: {len(test_not_in_train)}\")\n",
    "\n",
    "    return val_not_in_train, test_not_in_train\n",
    "\n",
    "# Assuming CSV files are named as follows:\n",
    "train_csv = 'relations_train.csv'\n",
    "val_csv = 'relations_val.csv'\n",
    "test_csv = 'relations_test.csv'\n",
    "\n",
    "# Check the ID coverage\n",
    "val_not_covered, test_not_covered = check_id_coverage(train_csv, val_csv, test_csv)\n",
    "\n",
    "# If you also want to see the specific IDs not covered, you can print val_not_covered and test_not_covered\n",
    "print(\"Validation IDs not in Train:\", val_not_covered)\n",
    "print(\"Test IDs not in Train:\", test_not_covered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation IDs not in Train: 29\n",
      "Test IDs not in Train: 66\n",
      "Validation Reaction IDs not in Train: {'cpd:C16221', 'cpd:C16173', 'cpd:C16220', 'cpd:C00999', 'cpd:C04088', 'cpd:C03691', 'cpd:C06508', 'cpd:C05399', 'cpd:C16217', 'cpd:C16300', 'cpd:C16216', 'cpd:C05774', 'cpd:C05400', 'cpd:C16218', 'cpd:C14818', 'cpd:C16375', 'cpd:C05401', 'cpd:C16389', 'cpd:C04079', 'cpd:C16388', 'cpd:C03410', 'cpd:C16374', 'cpd:C03688', 'cpd:C00054', 'cpd:C16376', 'cpd:C14819', 'cpd:C00996', 'cpd:C01235', 'cpd:C16387'}\n",
      "Test Reaction IDs not in Train: {'cpd:C16550', 'cpd:C15976', 'gl:G10794', 'cpd:C11583', 'cpd:C07644', 'cpd:C16549', 'cpd:C16608', 'dr:D04716 cpd:C08012', 'dr:D07704 cpd:C07572', 'cpd:C07645', 'gl:G13153', 'cpd:C16586', 'cpd:C15974', 'dr:D00399 cpd:C07185', 'cpd:C00027', 'dr:D08233 cpd:C01516', 'dr:D00358 cpd:C07073', 'cpd:C16546', 'cpd:C16551', 'cpd:C07643', 'cpd:C16578', 'dr:D00195 cpd:C06174', 'cpd:C00349', 'cpd:C11038', 'cpd:C06049', 'cpd:C16662', 'cpd:C16587', 'cpd:C16596', 'cpd:C16609', 'cpd:C16544', 'cpd:C04517', 'cpd:C16591', 'cpd:C16545', 'cpd:C16601', 'cpd:C16610', 'cpd:C16595', 'cpd:C16607', 'cpd:C16612', 'dr:D08195 cpd:C07163', 'cpd:C16576', 'cpd:C16582', 'cpd:C16604', 'cpd:C16660', 'dr:D08559 cpd:C07108', 'cpd:C11039', 'cpd:C07496', 'cpd:C16577', 'cpd:C16561', 'cpd:C16560', 'cpd:C16643', 'cpd:C16547', 'cpd:C16602', 'cpd:C00007', 'cpd:C15978', 'dr:D00252 cpd:C06868', 'dr:D00536 cpd:C07501', 'cpd:C16661', 'dr:D00343 cpd:C07047', 'cpd:C05011', 'cpd:C16584', 'cpd:C07646', 'cpd:C16651', 'cpd:C16553', 'dr:D07760 cpd:C07888', 'cpd:C16548', 'cpd:C16659'}\n"
     ]
    }
   ],
   "source": [
    "# Adjusted script to work with the provided reactions set structure\n",
    "\n",
    "def load_ids_from_csv(csv_file, id_fields):\n",
    "    unique_ids = set()\n",
    "    with open(csv_file, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            for id_field in id_fields:\n",
    "                if row[id_field] != '':  # Ensure the field is not empty\n",
    "                    unique_ids.add(row[id_field])\n",
    "    return unique_ids\n",
    "\n",
    "def remove_unseen_entities(data, train_ids, id_fields):\n",
    "    cleaned_data = []\n",
    "    for row in data:\n",
    "        if all(row[id_field] in train_ids or row[id_field] == '' for id_field in id_fields):\n",
    "            cleaned_data.append(row)\n",
    "    return cleaned_data\n",
    "\n",
    "def check_id_coverage_and_clean(train_csv, val_csv, test_csv, id_fields):\n",
    "    train_ids = load_ids_from_csv(train_csv, id_fields)\n",
    "    val_ids = load_ids_from_csv(val_csv, id_fields)\n",
    "    test_ids = load_ids_from_csv(test_csv, id_fields)\n",
    "\n",
    "    val_not_in_train = val_ids - train_ids\n",
    "    test_not_in_train = test_ids - train_ids\n",
    "\n",
    "    print(f\"Validation IDs not in Train: {len(val_not_in_train)}\")\n",
    "    print(f\"Test IDs not in Train: {len(test_not_in_train)}\")\n",
    "\n",
    "    # Load the actual data\n",
    "    val_data = load_data(val_csv)\n",
    "    test_data = load_data(test_csv)\n",
    "\n",
    "    # Clean the validation and test data\n",
    "    cleaned_val_data = remove_unseen_entities(val_data, train_ids, id_fields)\n",
    "    cleaned_test_data = remove_unseen_entities(test_data, train_ids, id_fields)\n",
    "\n",
    "    # Write the cleaned data to new CSV files\n",
    "    write_data(cleaned_val_data, 'cleaned_' + val_csv, val_data[0].keys())\n",
    "    write_data(cleaned_test_data, 'cleaned_' + test_csv, test_data[0].keys())\n",
    "\n",
    "    return val_not_in_train, test_not_in_train\n",
    "\n",
    "# Define the ID fields for reactions\n",
    "reaction_id_fields = [\n",
    "    'substrate1', 'substrate2', 'substrate3', 'substrate4', 'substrate5',\n",
    "    'product1', 'product2', 'product3', 'product4', 'product5'\n",
    "]\n",
    "\n",
    "# Assuming CSV files are named as follows:\n",
    "train_csv = 'reactions_train.csv'\n",
    "val_csv = 'reactions_val.csv'\n",
    "test_csv = 'reactions_test.csv'\n",
    "\n",
    "# Check the ID coverage and clean the datasets for reactions\n",
    "reactions_val_not_covered, reactions_test_not_covered = check_id_coverage_and_clean(\n",
    "    train_csv,\n",
    "    val_csv,\n",
    "    test_csv,\n",
    "    reaction_id_fields\n",
    ")\n",
    "\n",
    "# Output the number of entities not covered\n",
    "print(\"Validation Reaction IDs not in Train:\", reactions_val_not_covered)\n",
    "print(\"Test Reaction IDs not in Train:\", reactions_test_not_covered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Validation Set Count: 18133, Cleaned: 18128\n",
      "Original Test Set Count: 14220, Cleaned: 14173\n"
     ]
    }
   ],
   "source": [
    "# Adjusted script to work with the provided relations set structure\n",
    "import csv\n",
    "\n",
    "def load_data(csv_file):\n",
    "    with open(csv_file, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def load_ids_from_csv(csv_file, id_fields):\n",
    "    unique_ids = set()\n",
    "    with open(csv_file, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            # Check if the relation_type is not 'no_relation'\n",
    "            if row.get('relation_type', '') != 'no_relation':\n",
    "                for id_field in id_fields:\n",
    "                    if row[id_field] != '':  # Ensure the field is not empty\n",
    "                        unique_ids.add(row[id_field])\n",
    "    return unique_ids\n",
    "\n",
    "def remove_unseen_entities(data, train_ids, id_fields):\n",
    "    cleaned_data = []\n",
    "    for row in data:\n",
    "        if all(row[id_field] in train_ids or row[id_field] == '' for id_field in id_fields):\n",
    "            cleaned_data.append(row)\n",
    "    return cleaned_data\n",
    "\n",
    "def remove_unseen_entities_relations(data, train_ids):\n",
    "    cleaned_data = []\n",
    "    for row in data:\n",
    "        # Check if both starter and receiver IDs are in the training set\n",
    "        if row['starter_ID'] in train_ids and row['receiver_ID'] in train_ids:\n",
    "            cleaned_data.append(row)\n",
    "    return cleaned_data\n",
    "\n",
    "def write_data(data, filename, fieldnames):\n",
    "    with open(filename, mode='w', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "def check_id_coverage_and_clean_relations(train_csv, val_csv, test_csv):\n",
    "    # Load the unique IDs from the training set\n",
    "    train_ids = load_ids_from_csv(train_csv, ['starter_ID', 'receiver_ID'])\n",
    "    \n",
    "    # Load the validation and test sets\n",
    "    val_data = load_data(val_csv)\n",
    "    test_data = load_data(test_csv)\n",
    "    \n",
    "    # Clean the validation and test data by removing unseen entities\n",
    "    cleaned_val_data = remove_unseen_entities_relations(val_data, train_ids)\n",
    "    cleaned_test_data = remove_unseen_entities_relations(test_data, train_ids)\n",
    "\n",
    "    # Write the cleaned data to new CSV files\n",
    "    write_data(cleaned_val_data, 'cleaned_' + val_csv, val_data[0].keys())\n",
    "    write_data(cleaned_test_data, 'cleaned_' + test_csv, test_data[0].keys())\n",
    "\n",
    "    # Return the counts of the original and cleaned datasets for comparison\n",
    "    return len(val_data), len(cleaned_val_data), len(test_data), len(cleaned_test_data)\n",
    "\n",
    "# File paths for the relations datasets\n",
    "train_csv = 'relations_train_final.csv'\n",
    "val_csv = 'relations_val_final.csv'\n",
    "test_csv = 'relations_test_final.csv'\n",
    "\n",
    "# Check the ID coverage and clean the datasets for relations\n",
    "original_val_count, cleaned_val_count, original_test_count, cleaned_test_count = check_id_coverage_and_clean_relations(\n",
    "    train_csv, val_csv, test_csv\n",
    ")\n",
    "\n",
    "# Output the number of entities before and after cleaning\n",
    "print(f\"Original Validation Set Count: {original_val_count}, Cleaned: {cleaned_val_count}\")\n",
    "print(f\"Original Test Set Count: {original_test_count}, Cleaned: {cleaned_test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: relations_train.csv (Total Relations: 69339)\n",
      "  Subtype: compound, Count: 19259, Proportion: 0.28\n",
      "  Subtype: activation, Count: 27615, Proportion: 0.40\n",
      "  Subtype: phosphorylation, Count: 5023, Proportion: 0.07\n",
      "  Subtype: inhibition, Count: 6283, Proportion: 0.09\n",
      "  Subtype: expression, Count: 3163, Proportion: 0.05\n",
      "  Subtype: binding/association, Count: 5770, Proportion: 0.08\n",
      "  Subtype: dephosphorylation, Count: 1439, Proportion: 0.02\n",
      "  Subtype: dissociation, Count: 211, Proportion: 0.00\n",
      "  Subtype: ubiquitination, Count: 171, Proportion: 0.00\n",
      "  Subtype: methylation, Count: 8, Proportion: 0.00\n",
      "  Subtype: repression, Count: 102, Proportion: 0.00\n",
      "  Subtype: state change, Count: 249, Proportion: 0.00\n",
      "  Subtype: indirect, Count: 46, Proportion: 0.00\n",
      "\n",
      "\n",
      "File: cleaned_relations_val.csv (Total Relations: 12292)\n",
      "  Subtype: compound, Count: 708, Proportion: 0.06\n",
      "  Subtype: activation, Count: 7285, Proportion: 0.59\n",
      "  Subtype: phosphorylation, Count: 1042, Proportion: 0.08\n",
      "  Subtype: inhibition, Count: 1780, Proportion: 0.14\n",
      "  Subtype: binding/association, Count: 443, Proportion: 0.04\n",
      "  Subtype: dephosphorylation, Count: 215, Proportion: 0.02\n",
      "  Subtype: expression, Count: 729, Proportion: 0.06\n",
      "  Subtype: dissociation, Count: 40, Proportion: 0.00\n",
      "  Subtype: repression, Count: 8, Proportion: 0.00\n",
      "  Subtype: ubiquitination, Count: 6, Proportion: 0.00\n",
      "  Subtype: state change, Count: 36, Proportion: 0.00\n",
      "\n",
      "\n",
      "File: cleaned_relations_test.csv (Total Relations: 9645)\n",
      "  Subtype: compound, Count: 2652, Proportion: 0.27\n",
      "  Subtype: activation, Count: 4027, Proportion: 0.42\n",
      "  Subtype: binding/association, Count: 405, Proportion: 0.04\n",
      "  Subtype: expression, Count: 732, Proportion: 0.08\n",
      "  Subtype: phosphorylation, Count: 993, Proportion: 0.10\n",
      "  Subtype: inhibition, Count: 589, Proportion: 0.06\n",
      "  Subtype: state change, Count: 86, Proportion: 0.01\n",
      "  Subtype: dephosphorylation, Count: 89, Proportion: 0.01\n",
      "  Subtype: dissociation, Count: 40, Proportion: 0.00\n",
      "  Subtype: ubiquitination, Count: 4, Proportion: 0.00\n",
      "  Subtype: repression, Count: 28, Proportion: 0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def count_unique_subtypes_proportions(csv_file):\n",
    "    subtypes = Counter()\n",
    "    total_count = 0\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            subtypes[row['subtype_name']] += 1\n",
    "            total_count += 1\n",
    "    \n",
    "    proportions = {subtype: count / total_count for subtype, count in subtypes.items()}\n",
    "    return subtypes, proportions, total_count\n",
    "\n",
    "# Paths to the CSV files\n",
    "csv_files = ['relations_train.csv', 'cleaned_relations_val.csv', 'cleaned_relations_test.csv']\n",
    "\n",
    "# Count and print the number and proportion of each unique subtype_name in each file\n",
    "for csv_file in csv_files:\n",
    "    subtypes_count, proportions, total_count = count_unique_subtypes_proportions(csv_file)\n",
    "    print(f\"File: {csv_file} (Total Relations: {total_count})\")\n",
    "    for subtype, count in subtypes_count.items():\n",
    "        print(f\"  Subtype: {subtype}, Count: {count}, Proportion: {proportions[subtype]:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def load_csv(file_name):\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "def save_csv(df, file_name):\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "def generate_no_relation_entries(relations_df, all_relations):\n",
    "    no_relation_count = int(len(relations_df) * 0.5)\n",
    "    no_relation_entries = []\n",
    "\n",
    "    while len(no_relation_entries) < no_relation_count:\n",
    "        starter = random.choice(relations_df['starter_ID'])\n",
    "        receiver = random.choice(relations_df['receiver_ID'])\n",
    "\n",
    "        if (starter, receiver) not in all_relations and (receiver, starter) not in all_relations:\n",
    "            no_relation_entries.append([starter, receiver, 'no_relation', 'no_relation', 'no_relation', 'no_relation'])\n",
    "            all_relations.add((starter, receiver))\n",
    "            all_relations.add((receiver, starter))\n",
    "\n",
    "    no_relation_df = pd.DataFrame(no_relation_entries, columns=relations_df.columns)\n",
    "    return pd.concat([relations_df, no_relation_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Load existing relations\n",
    "train_relations = load_csv('relations_train.csv')\n",
    "val_relations = load_csv('cleaned_relations_val.csv')\n",
    "test_relations = load_csv('cleaned_relations_test.csv')\n",
    "\n",
    "# Combine all relations to ensure no duplicates\n",
    "all_relations = set()\n",
    "for df in [train_relations, val_relations, test_relations]:\n",
    "    for _, row in df.iterrows():\n",
    "        all_relations.add((row['starter_ID'], row['receiver_ID']))\n",
    "        all_relations.add((row['receiver_ID'], row['starter_ID']))\n",
    "\n",
    "# Generate 'no_relation' entries\n",
    "train_final = generate_no_relation_entries(train_relations, all_relations)\n",
    "val_final = generate_no_relation_entries(val_relations, all_relations)\n",
    "test_final = generate_no_relation_entries(test_relations, all_relations)\n",
    "\n",
    "# Save the final datasets\n",
    "save_csv(train_final, 'relations_train_final.csv')\n",
    "save_csv(val_final, 'relations_val_final.csv')\n",
    "save_csv(test_final, 'relations_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: relations_train_final.csv (Total Relations: 101786)\n",
      "  Subtype: compound, Count: 19259, Proportion: 0.19\n",
      "  Subtype: binding/association, Count: 5770, Proportion: 0.06\n",
      "  Subtype: activation, Count: 27615, Proportion: 0.27\n",
      "  Subtype: phosphorylation, Count: 5023, Proportion: 0.05\n",
      "  Subtype: no_relation, Count: 34669, Proportion: 0.34\n",
      "  Subtype: inhibition, Count: 6283, Proportion: 0.06\n",
      "  Subtype: expression, Count: 3163, Proportion: 0.03\n",
      "  Subtype: state change, Count: 4, Proportion: 0.00\n",
      "\n",
      "\n",
      "File: cleaned_relations_val_final.csv (Total Relations: 18129)\n",
      "  Subtype: no_relation, Count: 6143, Proportion: 0.34\n",
      "  Subtype: expression, Count: 729, Proportion: 0.04\n",
      "  Subtype: activation, Count: 7284, Proportion: 0.40\n",
      "  Subtype: phosphorylation, Count: 1042, Proportion: 0.06\n",
      "  Subtype: binding/association, Count: 443, Proportion: 0.02\n",
      "  Subtype: inhibition, Count: 1780, Proportion: 0.10\n",
      "  Subtype: compound, Count: 708, Proportion: 0.04\n",
      "\n",
      "\n",
      "File: cleaned_relations_test_final.csv (Total Relations: 14203)\n",
      "  Subtype: phosphorylation, Count: 993, Proportion: 0.07\n",
      "  Subtype: no_relation, Count: 4813, Proportion: 0.34\n",
      "  Subtype: activation, Count: 4019, Proportion: 0.28\n",
      "  Subtype: inhibition, Count: 589, Proportion: 0.04\n",
      "  Subtype: compound, Count: 2652, Proportion: 0.19\n",
      "  Subtype: binding/association, Count: 405, Proportion: 0.03\n",
      "  Subtype: expression, Count: 732, Proportion: 0.05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def count_unique_subtypes_proportions(csv_file):\n",
    "    subtypes = Counter()\n",
    "    total_count = 0\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            subtypes[row['subtype_name']] += 1\n",
    "            total_count += 1\n",
    "    \n",
    "    proportions = {subtype: count / total_count for subtype, count in subtypes.items()}\n",
    "    return subtypes, proportions, total_count\n",
    "\n",
    "# Paths to the CSV files\n",
    "csv_files = ['relations_train_final.csv', 'cleaned_relations_val_final.csv', 'cleaned_relations_test_final.csv']\n",
    "\n",
    "# Count and print the number and proportion of each unique subtype_name in each file\n",
    "for csv_file in csv_files:\n",
    "    subtypes_count, proportions, total_count = count_unique_subtypes_proportions(csv_file)\n",
    "    print(f\"File: {csv_file} (Total Relations: {total_count})\")\n",
    "    for subtype, count in subtypes_count.items():\n",
    "        print(f\"  Subtype: {subtype}, Count: {count}, Proportion: {proportions[subtype]:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "train_csv_path = 'relations_train_final.csv'\n",
    "val_csv_path = 'cleaned_relations_val_final.csv'\n",
    "test_csv_path = 'cleaned_relations_test_final.csv'\n",
    "\n",
    "# Define the weight mapping for each interaction type\n",
    "weight_mapping = {\n",
    "    'no_relation': 0,\n",
    "    'activation': 0.8,\n",
    "    'inhibition': 0.8,\n",
    "    'compound': 0.5,\n",
    "    'binding/association': 0.5,\n",
    "    'phosphorylation': 0.8,\n",
    "    'expression': 0.5\n",
    "}\n",
    "\n",
    "# Function to add weights to a CSV file based on the interaction type\n",
    "def add_weights_to_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['weight'] = df['subtype_name'].map(weight_mapping)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Add weights to each of the CSV files\n",
    "add_weights_to_csv(train_csv_path)\n",
    "add_weights_to_csv(val_csv_path)\n",
    "add_weights_to_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_removed': {'indirect': 46,\n",
       "  'dissociation': 211,\n",
       "  'methylation': 8,\n",
       "  'repression': 102,\n",
       "  'state change': 249,\n",
       "  'dephosphorylation': 1439,\n",
       "  'ubiquitination': 171},\n",
       " 'val_removed': {'indirect': 0,\n",
       "  'dissociation': 40,\n",
       "  'methylation': 0,\n",
       "  'repression': 8,\n",
       "  'state change': 36,\n",
       "  'dephosphorylation': 215,\n",
       "  'ubiquitination': 6},\n",
       " 'test_removed': {'indirect': 0,\n",
       "  'dissociation': 40,\n",
       "  'methylation': 0,\n",
       "  'repression': 28,\n",
       "  'state change': 86,\n",
       "  'dephosphorylation': 89,\n",
       "  'ubiquitination': 4}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "train_csv = 'relations_train_final.csv'\n",
    "val_csv = 'relations_val_final.csv'\n",
    "test_csv = 'relations_test_final.csv'\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Count the occurrences of each relation subtype in each set\n",
    "train_subtype_counts = train_df['subtype_name'].value_counts()\n",
    "val_subtype_counts = val_df['subtype_name'].value_counts()\n",
    "test_subtype_counts = test_df['subtype_name'].value_counts()\n",
    "\n",
    "# Determine the subtypes with less than 100 occurrences in each set\n",
    "subtypes_to_remove = set()\n",
    "\n",
    "for subtype, count in train_subtype_counts.items():\n",
    "    if count < 100:\n",
    "        subtypes_to_remove.add(subtype)\n",
    "\n",
    "for subtype, count in val_subtype_counts.items():\n",
    "    if count < 100:\n",
    "        subtypes_to_remove.add(subtype)\n",
    "\n",
    "for subtype, count in test_subtype_counts.items():\n",
    "    if count < 100:\n",
    "        subtypes_to_remove.add(subtype)\n",
    "\n",
    "# Remove the identified subtypes from each dataframe\n",
    "train_df = train_df[~train_df['subtype_name'].isin(subtypes_to_remove)]\n",
    "val_df = val_df[~val_df['subtype_name'].isin(subtypes_to_remove)]\n",
    "test_df = test_df[~test_df['subtype_name'].isin(subtypes_to_remove)]\n",
    "\n",
    "# Save the cleaned dataframes\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "test_df.to_csv(test_csv, index=False)\n",
    "\n",
    "# Report the subtypes removed and the count removed from each set\n",
    "removed_counts = {\n",
    "    \"train_removed\": {subtype: train_subtype_counts.get(subtype, 0) for subtype in subtypes_to_remove},\n",
    "    \"val_removed\": {subtype: val_subtype_counts.get(subtype, 0) for subtype in subtypes_to_remove},\n",
    "    \"test_removed\": {subtype: test_subtype_counts.get(subtype, 0) for subtype in subtypes_to_remove}\n",
    "}\n",
    "\n",
    "removed_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1525 unique entity IDs.\n",
      "Prefix: pat, Count: 38\n",
      "Prefix: hsa, Count: 1434\n",
      "Prefix: cpd, Count: 53\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def extract_unique_ids(relations_csv):\n",
    "    unique_ids = set()\n",
    "\n",
    "    # Extract from pathway_relations.csv\n",
    "    with open(relations_csv, mode='r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            unique_ids.add(row['starter_ID'])\n",
    "            unique_ids.add(row['receiver_ID'])\n",
    "\n",
    "    return unique_ids\n",
    "\n",
    "# Use the function to extract IDs\n",
    "relations_csv = 'cleaned_relations_test_final.csv'\n",
    "entity_ids = extract_unique_ids(relations_csv)\n",
    "\n",
    "# Now you have all unique entity IDs in the `entity_ids` set\n",
    "print(f\"Extracted {len(entity_ids)} unique entity IDs.\")\n",
    "\n",
    "def extract_unique_id_prefixes(unique_ids):\n",
    "    # Extract the first three characters of each ID and count their occurrences\n",
    "    prefix_counts = {}\n",
    "    for kegg_id in unique_ids:\n",
    "        # Extract the first three characters\n",
    "        prefix = kegg_id[:3]\n",
    "        if prefix:\n",
    "            prefix_counts[prefix] = prefix_counts.get(prefix, 0) + 1\n",
    "    return prefix_counts\n",
    "\n",
    "# Process the unique ID prefixes\n",
    "prefix_counts = extract_unique_id_prefixes(entity_ids)\n",
    "\n",
    "# Print the unique prefixes and their counts\n",
    "for prefix, count in prefix_counts.items():\n",
    "    print(f\"Prefix: {prefix}, Count: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathway_siamese_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
